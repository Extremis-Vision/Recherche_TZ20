{
  "query": "computational cost",
  "number_of_results": 0,
  "results": [
    {
      "url": "http://hdl.handle.net/10261/285530",
      "title": "Scheduling Success Ratios And Computational Cost Of The Mechanism",
      "content": "Peer reviewed",
      "engine": "openairedatasets",
      "parsed_url": [
        "http",
        "hdl.handle.net",
        "/10261/285530",
        "",
        "",
        ""
      ],
      "template": "default.html",
      "engines": [
        "openairedatasets"
      ],
      "positions": [
        1
      ],
      "score": 1.0,
      "category": "science"
    },
    {
      "url": "https://pubmed.ncbi.nlm.nih.gov/12646132",
      "title": "The Cost of Cortical Computation",
      "content": "Electrophysiological recordings show that individual neurons in cortex are strongly activated when engaged in appropriate tasks, but they tell us little about how many neurons might be engaged by a task, which is important to know if we are to understand how cortex encodes information. For human cortex, I estimate the cost of individual spikes, then, from the known energy consumption of cortex, I establish how many neurons can be active concurrently. The cost of a single spike is high, and this severely limits, possibly to fewer than 1%, the number of neurons that can be substantially active concurrently. The high cost of spikes requires the brain not only to use representational codes that rely on very few active neurons, but also to allocate its energy resources flexibly among cortical regions according to task demand. The latter constraint explains the investment in local control of hemodynamics, exploited by functional magnetic resonance imaging, and the need for mechanisms of selective attention.",
      "engine": "openairepublications",
      "parsed_url": [
        "https",
        "pubmed.ncbi.nlm.nih.gov",
        "/12646132",
        "",
        "",
        ""
      ],
      "template": "default.html",
      "engines": [
        "openairepublications"
      ],
      "positions": [
        1
      ],
      "score": 1.0,
      "category": "science"
    },
    {
      "url": "https://doi.org/10.1037/e557322013-001",
      "title": "A Change for the Better? Assessing the Computational Cost of Re-representation",
      "content": "",
      "engine": "openairedatasets",
      "parsed_url": [
        "https",
        "doi.org",
        "/10.1037/e557322013-001",
        "",
        "",
        ""
      ],
      "template": "default.html",
      "engines": [
        "openairedatasets"
      ],
      "positions": [
        2
      ],
      "score": 0.5,
      "category": "science"
    },
    {
      "url": "https://doi.org/10.1017/9781108868815.049",
      "title": "Cost of Computation",
      "content": "",
      "engine": "openairepublications",
      "parsed_url": [
        "https",
        "doi.org",
        "/10.1017/9781108868815.049",
        "",
        "",
        ""
      ],
      "template": "default.html",
      "engines": [
        "openairepublications"
      ],
      "positions": [
        2
      ],
      "score": 0.5,
      "category": "science"
    },
    {
      "url": "https://dx.doi.org/10.17632/b3y8pktb6h.1",
      "title": "Supplementary Material for: On the Accuracy and Computational Cost of Spiking Neuron Implementation",
      "content": "This data contains the Supplementary material for the paper \"On the Accuracy and Computational Cost of Spiking Neuron Implementation.\" This is divided into five folders: 1) Source code, 2) Raw data, 3) Calculations, 4) Tables, and 5) Figures. The Source code folder has the script files written in Python 3.7.3. There are two sub-folders inside this folder separating the scripts into constant and random input current tests, respectively. Each sub-folder has a separate Python script that performs a benchmark test for each Spiking Neuron (SN) model. The Raw data folder collects the data generated by executing the scripts in the Source code folder and by following the instructions in the Testing procedure section of the paper. This stores the raw data for several SNs, firing frequencies, and input currents. This folder has a sub-folder with several files recording the random input currents used in the benchmark tests. The Raw data folder also has two sub-folders with the benchmark test results, each for a specific stimulation current type. The Benchmark test sub-folders give the CPU execution time, the SCF (Spike Coincidence Factor), the VCF (Voltage Coincidence Factor), the last spike displacement, and the firing frequency for each Numerical Method (NM) and time step. Other four sub-folders are containing the spike-timing and voltage time course data. These data are separated into constant and random input currents and NM and time step. The Calculations folder gives two files in .xlsx format with several estimates used in the paper. These files collect the CPU time, SCF, VCF, last spike displacement, and firing frequency from Raw data folder and compute the CCF (Computational Cost Factor) and GPF (Global Performance Factor) for several SNs and firing frequencies. Also, these files calculate the average and increment/decrement percent in FLOPS, CPU time, CCF, SCF, VCF, last spike displacement, and GPF among several SNs and NMs. Furthermore, these files examine the balanced, lower limit, upper limit, Skocik-Long, and Izhikevich configurations mentioned in the paper. Fourth and fifth folders contain the supplementary tables and figures, respectively, referenced in the article.",
      "engine": "openairedatasets",
      "parsed_url": [
        "https",
        "dx.doi.org",
        "/10.17632/b3y8pktb6h.1",
        "",
        "",
        ""
      ],
      "template": "default.html",
      "engines": [
        "openairedatasets"
      ],
      "positions": [
        3
      ],
      "score": 0.3333333333333333,
      "category": "science"
    },
    {
      "url": "https://pubmed.ncbi.nlm.nih.gov/5825953",
      "title": "Costs, Care and the Computer",
      "content": "",
      "engine": "openairepublications",
      "parsed_url": [
        "https",
        "pubmed.ncbi.nlm.nih.gov",
        "/5825953",
        "",
        "",
        ""
      ],
      "template": "default.html",
      "engines": [
        "openairepublications"
      ],
      "positions": [
        3
      ],
      "score": 0.3333333333333333,
      "category": "science"
    },
    {
      "url": "https://dx.doi.org/10.17632/g8wpyyr3v9.1",
      "title": "Data for: Computing uncertainty for the optimum nitrogen rate using a generalized cost function",
      "content": "Maize grain yield response to nitrogen dataset, which includes dry grain yield for eight nitrogen rate treatments (0-235 kg ha-1) from Stewart, MN in 2012. There are a total of 32 observations across four replications. Nitrogen fertilizer was broadcast applied as urea and incorporated prior to planting. Total nitrogen uptake (grain, cob, and stover) at physiological maturity and total available nitrogen at planting (urea, ammonium, and nitrate) from 0 - 60 cm is also included.",
      "engine": "openairedatasets",
      "parsed_url": [
        "https",
        "dx.doi.org",
        "/10.17632/g8wpyyr3v9.1",
        "",
        "",
        ""
      ],
      "template": "default.html",
      "engines": [
        "openairedatasets"
      ],
      "positions": [
        4
      ],
      "score": 0.25,
      "category": "science"
    },
    {
      "url": "https://pubmed.ncbi.nlm.nih.gov/31955684",
      "title": "On the cost of iterative computations",
      "content": "With exascale-level computation on the horizon, the art of predicting the cost of computations has acquired a renewed focus. This task is especially challenging in the case of iterative methods, for which convergence behaviour often cannot be determined with certainty a priori (unless we are satisfied with potentially outrageous overestimates) and which typically suffer from performance bottlenecks at scale due to synchronization cost. Moreover, the amplification of rounding errors can substantially affect the practical performance, in particular for methods with short recurrences. In this article, we focus on what we consider to be key points which are crucial to understanding the cost of iteratively solving linear algebraic systems. This naturally leads us to questions on the place of numerical analysis in relation to mathematics, computer science and sciences, in general. This article is part of a discussion meeting issue ‘Numerical algorithms for high-performance computational science’.",
      "engine": "openairepublications",
      "parsed_url": [
        "https",
        "pubmed.ncbi.nlm.nih.gov",
        "/31955684",
        "",
        "",
        ""
      ],
      "template": "default.html",
      "engines": [
        "openairepublications"
      ],
      "positions": [
        4
      ],
      "score": 0.25,
      "category": "science"
    },
    {
      "url": "https://dx.doi.org/10.6084/m9.figshare.c.7419936",
      "title": "Cost-consequence analysis of computer vision-based skin prick tests: implications for cost containment in Switzerland",
      "content": "Abstract Background Skin prick tests (SPTs), or intraepidermal tests, are often the first diagnostic approach for people with a suspected allergy. Together with the clinical history, SPTs allow doctors to draw conclusions on allergies based on the sensitization pattern. The purpose of this study is to investigate the potential cost consequences that would accrue to a Swiss University hospital after the adoption of computer vision-based SPTs. Methods We conducted a cost-consequence analysis from a hospital’s perspective to evaluate the potential cost consequences of using a computer vision-based system to read SPT results. The patient population consisted of individuals who were referred to the allergology department of one of the five university hospitals in Switzerland, Inselspital, whose allergology department averages 100 SPTs a week. We developed an early cost-consequence model comparing two SPT techniques; computer vision-based SPTs conducted with the aid of Nexkin DSPT and standard fully manual SPTs. Probabilistic sensitivity analysis and additional univariate sensitivity analyses were used to account for uncertainty. Results The difference in average cost between the two alternatives from a hospital’s perspective was estimated to be CHF 7 per SPT, in favour of the computer vison-based SPTs. Monte Carlo probabilistic simulation also indicated that SPTs conducted using the computer vision-based system were cost saving compared to standard fully manual SPTs. Sensitivity analyses additionally demonstrated the robustness of the base case result subject to plausible changes in all the input parameters, with parameters representing the costs associated with both SPT techniques having the largest influence on the incremental cost. However, higher sensitization prevalence rates seemed to favour the more accurate standard fully manual SPTs. Conclusion Against the backdrop of rising healthcare costs especially in Switzerland, using computer-aided or (semi) automated diagnostic systems could play an important role in healthcare cost containment efforts. However, results should be taken with caution because of the uncertainty associated with the early nature of our analysis and the specific Swiss context adopted in this study.",
      "engine": "openairedatasets",
      "parsed_url": [
        "https",
        "dx.doi.org",
        "/10.6084/m9.figshare.c.7419936",
        "",
        "",
        ""
      ],
      "template": "default.html",
      "engines": [
        "openairedatasets"
      ],
      "positions": [
        5
      ],
      "score": 0.2,
      "category": "science"
    },
    {
      "template": "paper.html",
      "type": "pdf",
      "url": "https://ieeexplore.ieee.org/abstract/document/6208856/",
      "title": "Approaches for reducing the computational cost of interval type-2 fuzzy logic systems: overview and comparisons",
      "authors": [
        "D Wu"
      ],
      "publisher": null,
      "journal": "IEEE Transactions on Fuzzy Systems",
      "publishedDate": "2012-01-01T00:00:00",
      "content": "… to save computational cost or to … the computational cost of IT2 FLSs instead of comparing their performance, and the dynamic defuzzification method has the same computational cost as …",
      "comments": "",
      "html_url": null,
      "pdf_url": "https://lab.bciml.cn/wp-content/uploads/2020/08/Approaches-for-Reducing-the-Computational-Cost-of-Interval-Type-2-Fuzzy-Logic-Systems-Overview-and-Comparisons.pdf",
      "engine": "google scholar",
      "parsed_url": [
        "https",
        "ieeexplore.ieee.org",
        "/abstract/document/6208856/",
        "",
        "",
        ""
      ],
      "engines": [
        "google scholar"
      ],
      "positions": [
        1
      ],
      "score": 1.0,
      "category": "science"
    },
    {
      "template": "paper.html",
      "url": "http://arxiv.org/abs/2103.02355v1",
      "title": "Cost Optimal Planning as Satisfiability",
      "publishedDate": "2021-03-03T12:18:18",
      "content": "We investigate upper bounds on the length of cost optimal plans that are valid for problems with 0-cost actions. We employ these upper bounds as horizons for a SAT-based encoding of planning with costs. Given an initial upper bound on the cost of the optimal plan, we experimentally show that this SAT-based approach is able to compute plans with better costs, and in many cases it can match the optimal cost. Also, in multiple instances, the approach is successful in proving that a certain cost is the optimal plan cost.",
      "doi": null,
      "authors": [
        "Mohammad Abdulaziz"
      ],
      "journal": null,
      "tags": [
        "cs.AI",
        "cs.LO",
        "F.2.2; F.4.1"
      ],
      "comments": null,
      "pdf_url": "http://arxiv.org/pdf/2103.02355v1",
      "engine": "arxiv",
      "parsed_url": [
        "http",
        "arxiv.org",
        "/abs/2103.02355v1",
        "",
        "",
        ""
      ],
      "engines": [
        "arxiv"
      ],
      "positions": [
        1
      ],
      "score": 1.0,
      "category": "science"
    },
    {
      "template": "paper.html",
      "type": "pdf",
      "url": "https://www.tandfonline.com/doi/abs/10.1080/01621459.2012.737745",
      "title": "Optimal detection of changepoints with a linear computational cost",
      "authors": [
        "R Killick",
        "P Fearnhead",
        "IA Eckley"
      ],
      "publisher": "Taylor & Francis",
      "journal": "Journal of the American …",
      "publishedDate": "2012-01-01T00:00:00",
      "content": "… cost functions and hence the optimal number and location of changepoints that has a computational cost… for the same problem whose computational cost can be quadratic or even …",
      "comments": "",
      "html_url": null,
      "pdf_url": "https://arxiv.org/pdf/1101.1438",
      "engine": "google scholar",
      "parsed_url": [
        "https",
        "www.tandfonline.com",
        "/doi/abs/10.1080/01621459.2012.737745",
        "",
        "",
        ""
      ],
      "engines": [
        "google scholar"
      ],
      "positions": [
        2
      ],
      "score": 0.5,
      "category": "science"
    },
    {
      "template": "paper.html",
      "url": "http://arxiv.org/abs/1109.2232v1",
      "title": "A New Proposed Cost Model for List Accessing Problem using Buffering",
      "publishedDate": "2011-09-10T15:44:34",
      "content": "There are many existing well known cost models for the list accessing problem. The standard cost model developed by Sleator and Tarjan is most widely used. In this paper, we have made a comprehensive study of the existing cost models and proposed a new cost model for the list accessing problem. In our proposed cost model, for calculating the processing cost of request sequence using a singly linked list, we consider the access cost, matching cost and replacement cost. The cost of processing a request sequence is the sum of access cost, matching cost and replacement cost. We have proposed a novel method for processing the request sequence which does not consider the rearrangement of the list and uses the concept of buffering, matching, look ahead and flag bit.",
      "doi": "10.5120/2604-3631",
      "authors": [
        "Rakesh Mohanty",
        "Seetaya Bhoi",
        "Sasmita Tripathy"
      ],
      "journal": "International Journal of Computer Applications, Volume 22-- No.8,\n  May 2011",
      "tags": [
        "cs.DS"
      ],
      "comments": "05 Pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/1109.2232v1",
      "engine": "arxiv",
      "parsed_url": [
        "http",
        "arxiv.org",
        "/abs/1109.2232v1",
        "",
        "",
        ""
      ],
      "engines": [
        "arxiv"
      ],
      "positions": [
        2
      ],
      "score": 0.5,
      "category": "science"
    },
    {
      "template": "paper.html",
      "type": "",
      "url": "https://pubs.acs.org/doi/abs/10.1021/ar700208h",
      "title": "Theoretical thermodynamics for large molecules: walking the thin line between accuracy and computational cost",
      "authors": [
        "T Schwabe",
        "S Grimme"
      ],
      "publisher": "ACS Publications",
      "journal": "Accounts of chemical research",
      "publishedDate": "2008-01-01T00:00:00",
      "content": "… Because of the fewer number of individual calculation steps that also have a lower computational cost, our approaches are much simpler to perform. They are explained in detail in ref …",
      "comments": "",
      "html_url": null,
      "pdf_url": null,
      "engine": "google scholar",
      "parsed_url": [
        "https",
        "pubs.acs.org",
        "/doi/abs/10.1021/ar700208h",
        "",
        "",
        ""
      ],
      "engines": [
        "google scholar"
      ],
      "positions": [
        3
      ],
      "score": 0.3333333333333333,
      "category": "science"
    },
    {
      "template": "paper.html",
      "url": "http://arxiv.org/abs/2309.04954v1",
      "title": "A Penny a Function: Towards Cost Transparent Cloud Programming",
      "publishedDate": "2023-09-10T08:02:12",
      "content": "Understanding and managing monetary cost factors is crucial when developing cloud applications. However, the diverse range of factors influencing costs for computation, storage, and networking in cloud applications poses a challenge for developers who want to manage and minimize costs proactively. Existing tools for understanding cost factors are often detached from source code, causing opaqueness regarding the origin of costs. Moreover, existing cost models for cloud applications focus on specific factors such as compute resources and necessitate manual effort to create the models. This paper presents initial work toward a cost model based on a directed graph that allows deriving monetary cost estimations directly from code using static analysis. Leveraging the cost model, we explore visualizations embedded in a code editor that display costs close to the code causing them. This makes cost exploration an integrated part of the developer experience, thereby removing the overhead of external tooling for cost estimation of cloud applications at development time.",
      "doi": null,
      "authors": [
        "Lukas Böhme",
        "Tom Beckmann",
        "Sebastian Baltes",
        "Robert Hirschfeld"
      ],
      "journal": null,
      "tags": [
        "cs.SE"
      ],
      "comments": "Proceedings of the 2nd ACM SIGPLAN International Workshop on\n  Programming Abstractions and Interactive Notations, Tools, and Environments\n  (PAINT 2023), 10 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2309.04954v1",
      "engine": "arxiv",
      "parsed_url": [
        "http",
        "arxiv.org",
        "/abs/2309.04954v1",
        "",
        "",
        ""
      ],
      "engines": [
        "arxiv"
      ],
      "positions": [
        3
      ],
      "score": 0.3333333333333333,
      "category": "science"
    },
    {
      "template": "paper.html",
      "type": "pdf",
      "url": "https://ieeexplore.ieee.org/abstract/document/8622396/",
      "title": "Predicting the computational cost of deep learning models",
      "authors": [
        "D Justus",
        "J Brennan",
        "S Bonner…"
      ],
      "publisher": null,
      "journal": "2018 IEEE international …",
      "publishedDate": "2018-01-01T00:00:00",
      "content": "… on ‘features’ derived from the computational resource used, the … a broad view of cost including financial and execution cost. … help to reduce the computational time to train our approach …",
      "comments": "",
      "html_url": null,
      "pdf_url": "https://arxiv.org/pdf/1811.11880",
      "engine": "google scholar",
      "parsed_url": [
        "https",
        "ieeexplore.ieee.org",
        "/abstract/document/8622396/",
        "",
        "",
        ""
      ],
      "engines": [
        "google scholar"
      ],
      "positions": [
        4
      ],
      "score": 0.25,
      "category": "science"
    },
    {
      "template": "paper.html",
      "url": "http://arxiv.org/abs/2107.03040v2",
      "title": "Capacitated Network Design Games on a Generalized Fair Allocation Model",
      "publishedDate": "2021-07-07T06:46:46",
      "content": "The cost-sharing connection game is a variant of routing games on a network. In this model, given a directed graph with edge costs and edge capacities, each agent wants to construct a path from a source to a sink with low cost. The users share the cost of each edge based on a cost-sharing function. One of the simple cost-sharing functions is defined as the cost divided by the number of users. Most of the previous papers about cost-sharing connection games addressed this cost-sharing function. It models an ideal setting where no overhead arises when people share things, though it might be quite rare in real life; it is more realistic to consider the setting that the cost paid by an agent is the original cost per the number of agents using the edge plus the overhead. In this paper, we model the more realistic scenario of cost-sharing connection games by generalizing cost-sharing functions. The arguments on the model are based on not concrete cost-sharing functions but cost-sharing functions under a reasonable scheme; they are applicable for a broad class of cost-sharing functions satisfying the following natural properties: they are (1) non-increasing, (2) lower bounded by the original cost per the number of the agents, and (3) upper bounded by the original cost, which enables to represent various scenarios of cost-sharing. We investigate the Price of Anarchy (PoA) and the Price of Stability (PoS) under sum-cost and max-cost criteria with the generalized cost-sharing function. Despite the generalization, we obtain the same tight bounds of PoA and PoS as the cost-sharing with no overhead except PoS under sum-cost. Moreover, for the sum-cost case, the lower bound on PoS increases from $\\log n$ to $n+1/n-1$ by the generalization, which is also almost tight because the upper bound is $n$.",
      "doi": null,
      "authors": [
        "Tesshu Hanaka",
        "Toshiyuki Hirose",
        "Hirotaka Ono"
      ],
      "journal": null,
      "tags": [
        "cs.GT"
      ],
      "comments": "14 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2107.03040v2",
      "engine": "arxiv",
      "parsed_url": [
        "http",
        "arxiv.org",
        "/abs/2107.03040v2",
        "",
        "",
        ""
      ],
      "engines": [
        "arxiv"
      ],
      "positions": [
        4
      ],
      "score": 0.25,
      "category": "science"
    },
    {
      "template": "paper.html",
      "type": "pdf",
      "url": "https://academic.oup.com/biomet/article-abstract/97/2/447/219260",
      "title": "A sequential smoothing algorithm with linear computational cost",
      "authors": [
        "P Fearnhead",
        "D Wyncoll",
        "J Tawn"
      ],
      "publisher": null,
      "journal": "Biometrika",
      "publishedDate": "2010-01-01T00:00:00",
      "content": "… This compares favourably with the O(N2) computational cost … for practical amounts of computational cost. It is shown both … the only other smoother with computational cost that is O(N). …",
      "comments": "",
      "html_url": null,
      "pdf_url": "https://www.researchgate.net/profile/Paul-Fearnhead/publication/227464410_A_sequential_smoothing_algorithm_with_linear_computational_cost/links/0912f51399e39a3e6d000000/A-sequential-smoothing-algorithm-with-linear-computational-cost.pdf",
      "engine": "google scholar",
      "parsed_url": [
        "https",
        "academic.oup.com",
        "/biomet/article-abstract/97/2/447/219260",
        "",
        "",
        ""
      ],
      "engines": [
        "google scholar"
      ],
      "positions": [
        5
      ],
      "score": 0.2,
      "category": "science"
    },
    {
      "url": "http://arxiv.org/pdf/quant-ph/0701237",
      "title": "Thermodynamical cost of reversible computing",
      "content": "Since reversible computing requires preservation of all information throughout the entire computational process, this implies that all errors that appear as a result of the interaction of the information-carrying system with uncontrolled degrees of freedom must be corrected. But this can only be done at the expense of an increase in the entropy of the environment corresponding to the dissipation, in the form of heat, of the ``noisy'' part of the system's energy. This paper gives an expression of that energy in terms of the effective noise temperature, and analyzes the relationship between the energy dissipation rate and the rate of computation. Finally, a generalized Clausius principle based on the concept of effective temperature is presented.",
      "engine": "openairepublications",
      "parsed_url": [
        "http",
        "arxiv.org",
        "/pdf/quant-ph/0701237",
        "",
        "",
        ""
      ],
      "template": "default.html",
      "engines": [
        "openairepublications"
      ],
      "positions": [
        5
      ],
      "score": 0.2,
      "category": "science"
    },
    {
      "url": "https://dx.doi.org/10.5281/zenodo.11261560",
      "title": "Cost Management in Cloud Computing: a study on financial waste and correction strategies",
      "content": "This project explores the identification and mitigation of financial wastage in Cloud Computing (CC) operations by professionals in the field, examining the alignment of their strategies with FinOps guidelines. Through a survey distributed via social media and messaging apps to CC professionals, the study engaged 28 participants from various companies, sizes, and sectors. It revealed that these professionals have encountered cost-related issues in cloud applications, particularly financial wastage. The investigation aimed to understand the prevalence of financial wastage in CC and evaluate the effectiveness of the adopted practices in addressing these inefficiencies within the framework of FinOps principles.",
      "engine": "openairedatasets",
      "parsed_url": [
        "https",
        "dx.doi.org",
        "/10.5281/zenodo.11261560",
        "",
        "",
        ""
      ],
      "template": "default.html",
      "engines": [
        "openairedatasets"
      ],
      "positions": [
        6
      ],
      "score": 0.16666666666666666,
      "category": "science"
    },
    {
      "url": "https://doi.org/10.1007/978-3-319-11203-9_17",
      "title": "Verifiable Computation with Reduced Informational Costs and Computational Costs",
      "content": "Outsourcing computation is a fundamental principle of the new cloud computing paradigm. Among its various aspects, the correctness of the computation result remains paramount. This motivates the birth of verifiable computation, which aims at efficiently checking the result for general-purpose computation. The common goal of recently sprouted verifiable computation protocols is to reduce the costs associated with verification at both prover and verifier. Unfortunately, the high computation and communication costs of verification still keep general verifiable computation away from practicality. Besides the computational costs, we observe that another type of verification cost has been generally ignored until now –the informational costs, namely, the information required for the verification. In particular, in the context of the third-party verification, this cost implies the information leakage of sensitive information regarding the computational task and its results. In this paper, we introduce the new verifiable-computation protocol RIVER, which reduces the computational costs of the verifier and of the prover, comparing to the most recent alternative protocols, and (for the first time in the context of verifiable computation) addresses and decreases informational costs.",
      "engine": "openairepublications",
      "parsed_url": [
        "https",
        "doi.org",
        "/10.1007/978-3-319-11203-9_17",
        "",
        "",
        ""
      ],
      "template": "default.html",
      "engines": [
        "openairepublications"
      ],
      "positions": [
        6
      ],
      "score": 0.16666666666666666,
      "category": "science"
    },
    {
      "url": "https://dx.doi.org/10.5281/zenodo.11246014",
      "title": "Cost Management in Cloud Computing: a study on financial waste and correction strategies",
      "content": "This project explores the identification and mitigation of financial wastage in Cloud Computing (CC) operations by professionals in the field, examining the alignment of their strategies with FinOps guidelines. Through a survey distributed via social media and messaging apps to CC professionals, the study engaged 28 participants from various companies, sizes, and sectors. It revealed that these professionals have encountered cost-related issues in cloud applications, particularly financial wastage. The investigation aimed to understand the prevalence of financial wastage in CC and evaluate the effectiveness of the adopted practices in addressing these inefficiencies within the framework of FinOps principles.",
      "engine": "openairedatasets",
      "parsed_url": [
        "https",
        "dx.doi.org",
        "/10.5281/zenodo.11246014",
        "",
        "",
        ""
      ],
      "template": "default.html",
      "engines": [
        "openairedatasets"
      ],
      "positions": [
        7
      ],
      "score": 0.14285714285714285,
      "category": "science"
    },
    {
      "url": "https://doi.org/10.1145/846153.846154",
      "title": "Lowering the cost of computation",
      "content": "Efficient support for sophisticated interactions between entities in distributed brokering systems",
      "engine": "openairepublications",
      "parsed_url": [
        "https",
        "doi.org",
        "/10.1145/846153.846154",
        "",
        "",
        ""
      ],
      "template": "default.html",
      "engines": [
        "openairepublications"
      ],
      "positions": [
        7
      ],
      "score": 0.14285714285714285,
      "category": "science"
    },
    {
      "url": "http://data.europa.eu/88u/dataset/low-cost-free-computer-access",
      "title": "Low Cost/Free Computer Access",
      "content": "Location of Low-cost or free computer access. Upon accessing this Licensed Data you will be deemed to have accepted the terms of the Public Sector End User Licence - INSPIRE.",
      "engine": "openairedatasets",
      "parsed_url": [
        "http",
        "data.europa.eu",
        "/88u/dataset/low-cost-free-computer-access",
        "",
        "",
        ""
      ],
      "template": "default.html",
      "engines": [
        "openairedatasets"
      ],
      "positions": [
        8
      ],
      "score": 0.125,
      "category": "science"
    },
    {
      "url": "https://pubmed.ncbi.nlm.nih.gov/23045633",
      "title": "Energetic costs of cellular computation",
      "content": "Cells often perform computations in order to respond to environmental cues. A simple example is the classic problem, first considered by Berg and Purcell, of determining the concentration of a chemical ligand in the surrounding media. On general theoretical grounds, it is expected that such computations require cells to consume energy. In particular, Landauer’s principle states that energy must be consumed in order to erase the memory of past observations. Here, we explicitly calculate the energetic cost of steady-state computation of ligand concentration for a simple two-component cellular network that implements a noisy version of the Berg–Purcell strategy. We show that learning about external concentrations necessitates the breaking of detailed balance and consumption of energy, with greater learning requiring more energy. Our calculations suggest that the energetic costs of cellular computation may be an important constraint on networks designed to function in resource poor environments, such as the spore germination networks of bacteria.",
      "engine": "openairepublications",
      "parsed_url": [
        "https",
        "pubmed.ncbi.nlm.nih.gov",
        "/23045633",
        "",
        "",
        ""
      ],
      "template": "default.html",
      "engines": [
        "openairepublications"
      ],
      "positions": [
        8
      ],
      "score": 0.125,
      "category": "science"
    },
    {
      "url": "https://doi.org/10.1257/rct.3405-2.0",
      "title": "Incentive Contracts, Effort Costs, and Productivity in Teams and Individuals: Experimental Evidence from Computer Programmers",
      "content": "",
      "engine": "openairedatasets",
      "parsed_url": [
        "https",
        "doi.org",
        "/10.1257/rct.3405-2.0",
        "",
        "",
        ""
      ],
      "template": "default.html",
      "engines": [
        "openairedatasets"
      ],
      "positions": [
        9
      ],
      "score": 0.1111111111111111,
      "category": "science"
    },
    {
      "url": "https://doi.org/10.1063/1.3022057",
      "title": "Computer learning costs",
      "content": "",
      "engine": "openairepublications",
      "parsed_url": [
        "https",
        "doi.org",
        "/10.1063/1.3022057",
        "",
        "",
        ""
      ],
      "template": "default.html",
      "engines": [
        "openairepublications"
      ],
      "positions": [
        9
      ],
      "score": 0.1111111111111111,
      "category": "science"
    },
    {
      "template": "paper.html",
      "url": "http://arxiv.org/abs/1104.0617v1",
      "title": "Computing Optimal Coverability Costs in Priced Timed Petri Nets",
      "publishedDate": "2011-04-04T16:35:01",
      "content": "We consider timed Petri nets, i.e., unbounded Petri nets where each token carries a real-valued clock. Transition arcs are labeled with time intervals, which specify constraints on the ages of tokens. Our cost model assigns token storage costs per time unit to places, and firing costs to transitions. We study the cost to reach a given control-state. In general, a cost-optimal run may not exist. However, we show that the infimum of the costs is computable.",
      "doi": null,
      "authors": [
        "Parosh Aziz Abdulla",
        "Richard Mayr"
      ],
      "journal": null,
      "tags": [
        "cs.LO",
        "F.1.1; F.3.1"
      ],
      "comments": "26 pages. Contribution to LICS 2011",
      "pdf_url": "http://arxiv.org/pdf/1104.0617v1",
      "engine": "arxiv",
      "parsed_url": [
        "http",
        "arxiv.org",
        "/abs/1104.0617v1",
        "",
        "",
        ""
      ],
      "engines": [
        "arxiv"
      ],
      "positions": [
        5
      ],
      "score": 0.2,
      "category": "science"
    },
    {
      "template": "paper.html",
      "type": "pdf",
      "url": "https://www.jstor.org/stable/26408299",
      "title": "Importance sampling: Intrinsic dimension and computational cost",
      "authors": [
        "S Agapiou",
        "O Papaspiliopoulos",
        "D Sanz-Alonso…"
      ],
      "publisher": "JSTOR",
      "journal": "Statistical Science",
      "publishedDate": "2017-01-01T00:00:00",
      "content": "… key in understand ing the computational cost of importance sampling and the central role played by p. In this section, we study the computational cost of importance sampling applied in …",
      "comments": "",
      "html_url": null,
      "pdf_url": "https://projecteuclid.org/journals/statistical-science/volume-32/issue-3/Importance-Sampling-Intrinsic-Dimension-and-Computational-Cost/10.1214/17-STS611.pdf",
      "engine": "google scholar",
      "parsed_url": [
        "https",
        "www.jstor.org",
        "/stable/26408299",
        "",
        "",
        ""
      ],
      "engines": [
        "google scholar"
      ],
      "positions": [
        6
      ],
      "score": 0.16666666666666666,
      "category": "science"
    },
    {
      "template": "paper.html",
      "url": "http://arxiv.org/abs/1503.06384v1",
      "title": "Costing Generated Runtime Execution Plans for Large-Scale Machine Learning Programs",
      "publishedDate": "2015-03-22T05:00:08",
      "content": "Declarative large-scale machine learning (ML) aims at the specification of ML algorithms in a high-level language and automatic generation of hybrid runtime execution plans ranging from single node, in-memory computations to distributed computations on MapReduce (MR) or similar frameworks like Spark. The compilation of large-scale ML programs exhibits many opportunities for automatic optimization. Advanced cost-based optimization techniques require---as a fundamental precondition---an accurate cost model for evaluating the impact of optimization decisions. In this paper, we share insights into a simple and robust yet accurate technique for costing alternative runtime execution plans of ML programs. Our cost model relies on generating and costing runtime plans in order to automatically reflect all successive optimization phases. Costing runtime plans also captures control flow structures such as loops and branches, and a variety of cost factors like IO, latency, and computation costs. Finally, we linearize all these cost factors into a single measure of expected execution time. Within SystemML, this cost model is leveraged by several advanced optimizers like resource optimization and global data flow optimization. We share our lessons learned in order to provide foundations for the optimization of ML programs.",
      "doi": null,
      "authors": [
        "Matthias Boehm"
      ],
      "journal": null,
      "tags": [
        "cs.DC",
        "cs.LG"
      ],
      "comments": null,
      "pdf_url": "http://arxiv.org/pdf/1503.06384v1",
      "engine": "arxiv",
      "parsed_url": [
        "http",
        "arxiv.org",
        "/abs/1503.06384v1",
        "",
        "",
        ""
      ],
      "engines": [
        "arxiv"
      ],
      "positions": [
        6
      ],
      "score": 0.16666666666666666,
      "category": "science"
    },
    {
      "template": "paper.html",
      "type": "pdf",
      "url": "https://link.springer.com/article/10.1007/BF01536399",
      "title": "On the computational cost of disjunctive logic programming: Propositional case",
      "authors": [
        "T Eiter",
        "G Gottlob"
      ],
      "publisher": "Springer",
      "journal": "Annals of Mathematics and Artificial Intelligence",
      "publishedDate": "1995-01-01T00:00:00",
      "content": "This paper addresses complexity issues for important problems arising with disjunctive logic programming. In particular, the complexity of deciding whether a disjunctive logic program …",
      "comments": "",
      "html_url": null,
      "pdf_url": "https://www.kr.tuwien.ac.at/staff/eiter/et-archive/files/amai-dlp.pdf",
      "engine": "google scholar",
      "parsed_url": [
        "https",
        "link.springer.com",
        "/article/10.1007/BF01536399",
        "",
        "",
        ""
      ],
      "engines": [
        "google scholar"
      ],
      "positions": [
        7
      ],
      "score": 0.14285714285714285,
      "category": "science"
    },
    {
      "template": "paper.html",
      "url": "http://arxiv.org/abs/2103.15302v1",
      "title": "Analytic formula for option margin with liquidity costs under dynamic delta hedging",
      "publishedDate": "2021-03-29T03:18:09",
      "content": "This study derives the expected liquidity cost when performing the delta hedging process of a European option. This cost is represented by an integration formula that includes European option prices and a certain function depending on the delta process. We first define a unit liquidity cost and then show that the liquidity cost is a multiplication of the unit liquidity cost, stock price, supply curve parameter, and the square of the number of options. Using this formula, the expected liquidity cost before hedging can be calculated much faster than when using a Monte Carlo simulation. Numerically computed distributions of liquidity costs in special cases are also provided.",
      "doi": "10.1080/00036846.2021.1881430",
      "authors": [
        "Kyungsub Lee",
        "Byoung Ki Seo"
      ],
      "journal": null,
      "tags": [
        "q-fin.PR",
        "q-fin.TR"
      ],
      "comments": null,
      "pdf_url": "http://arxiv.org/pdf/2103.15302v1",
      "engine": "arxiv",
      "parsed_url": [
        "http",
        "arxiv.org",
        "/abs/2103.15302v1",
        "",
        "",
        ""
      ],
      "engines": [
        "arxiv"
      ],
      "positions": [
        7
      ],
      "score": 0.14285714285714285,
      "category": "science"
    },
    {
      "template": "paper.html",
      "type": "pdf",
      "url": "https://www.sciencedirect.com/science/article/pii/0004370295000569",
      "title": "Critical behavior in the computational cost of satisfiability testing",
      "authors": [
        "B Selman",
        "S Kirkpatrick"
      ],
      "publisher": "Elsevier",
      "journal": "Artificial Intelligence",
      "publishedDate": "1996-01-01T00:00:00",
      "content": "… critical behavior in the computational cost. We find that the median computational cost takes on a … of the complexity by studying distributions of computational cost. In the SAT phase we …",
      "comments": "",
      "html_url": null,
      "pdf_url": "https://www.sciencedirect.com/science/article/pii/0004370295000569/pdf?md5=1bfe4d42e29fa9a0a8d9680b5924b228&pid=1-s2.0-0004370295000569-main.pdf",
      "engine": "google scholar",
      "parsed_url": [
        "https",
        "www.sciencedirect.com",
        "/science/article/pii/0004370295000569",
        "",
        "",
        ""
      ],
      "engines": [
        "google scholar"
      ],
      "positions": [
        8
      ],
      "score": 0.125,
      "category": "science"
    },
    {
      "template": "paper.html",
      "url": "http://arxiv.org/abs/1602.07827v3",
      "title": "Minimum Cost Homomorphisms with Constrained Costs",
      "publishedDate": "2016-02-25T07:34:37",
      "content": "Minimum cost homomorphism problems can be viewed as a generalization of list homomorphism problems. They also extend two well-known graph colouring problems: the minimum colour sum problem and the optimum cost chromatic partition problem. In both of these problems, the cost function meets an additional constraint: the cost of using a specific colour is the same for every vertex of the input graph. We study minimum cost homomorphism problems with cost functions constrained to have this property. Clearly, when the standard minimum cost homomorphism problem is polynomial, then the problem with constrained costs is also polynomial. We expect that the same may hold for the cases when the standard minimum cost homomorphism problem is NP-complete. We prove that this is the case for trees $H$: we obtain a dichotomy of minimum constrained cost homomorphism problems which coincides with the dichotomy of standard minimum cost homomorphism problems. For general graphs $H$, we prove a partial dichotomy: the problem is polynomial if $H$ is a proper interval graph and NP-complete when $H$ is not chordal bipartite.",
      "doi": null,
      "authors": [
        "Pavol Hell",
        "Mayssam Mohammadi Nevisi"
      ],
      "journal": null,
      "tags": [
        "cs.CC",
        "math.CO"
      ],
      "comments": null,
      "pdf_url": "http://arxiv.org/pdf/1602.07827v3",
      "engine": "arxiv",
      "parsed_url": [
        "http",
        "arxiv.org",
        "/abs/1602.07827v3",
        "",
        "",
        ""
      ],
      "engines": [
        "arxiv"
      ],
      "positions": [
        8
      ],
      "score": 0.125,
      "category": "science"
    },
    {
      "template": "paper.html",
      "type": "pdf",
      "url": "https://ieeexplore.ieee.org/abstract/document/7515194/",
      "title": "Automatic environmental sound recognition: Performance versus computational cost",
      "authors": [
        "S Sigtia",
        "AM Stark",
        "S Krstulović…"
      ],
      "publisher": null,
      "journal": "IEEE/ACM Transactions …",
      "publishedDate": "2016-01-01T00:00:00",
      "content": "… Whereas Automatic Environmental Sound Recognition (AESR) algorithms are most often developed with limited consideration for computational cost, this paper seeks which AESR …",
      "comments": "",
      "html_url": null,
      "pdf_url": "https://arxiv.org/pdf/1607.04589",
      "engine": "google scholar",
      "parsed_url": [
        "https",
        "ieeexplore.ieee.org",
        "/abstract/document/7515194/",
        "",
        "",
        ""
      ],
      "engines": [
        "google scholar"
      ],
      "positions": [
        9
      ],
      "score": 0.1111111111111111,
      "category": "science"
    },
    {
      "template": "paper.html",
      "url": "http://arxiv.org/abs/1412.4456v2",
      "title": "Sharing Non-Anonymous Costs of Multiple Resources Optimally",
      "publishedDate": "2014-12-15T04:17:41",
      "content": "In cost sharing games, the existence and efficiency of pure Nash equilibria fundamentally depends on the method that is used to share the resources' costs. We consider a general class of resource allocation problems in which a set of resources is used by a heterogeneous set of selfish users. The cost of a resource is a (non-decreasing) function of the set of its users. Under the assumption that the costs of the resources are shared by uniform cost sharing protocols, i.e., protocols that use only local information of the resource's cost structure and its users to determine the cost shares, we exactly quantify the inefficiency of the resulting pure Nash equilibria. Specifically, we show tight bounds on prices of stability and anarchy for games with only submodular and only supermodular cost functions, respectively, and an asymptotically tight bound for games with arbitrary set-functions. While all our upper bounds are attained for the well-known Shapley cost sharing protocol, our lower bounds hold for arbitrary uniform cost sharing protocols and are even valid for games with anonymous costs, i.e., games in which the cost of each resource only depends on the cardinality of the set of its users.",
      "doi": null,
      "authors": [
        "Max Klimm",
        "Daniel Schmand"
      ],
      "journal": null,
      "tags": [
        "cs.GT"
      ],
      "comments": null,
      "pdf_url": "http://arxiv.org/pdf/1412.4456v2",
      "engine": "arxiv",
      "parsed_url": [
        "http",
        "arxiv.org",
        "/abs/1412.4456v2",
        "",
        "",
        ""
      ],
      "engines": [
        "arxiv"
      ],
      "positions": [
        9
      ],
      "score": 0.1111111111111111,
      "category": "science"
    },
    {
      "url": "https://doi.org/10.1037/e578892011-002",
      "title": "Assessing the Cost of Underperformance: A Computer Programmer Example",
      "content": "",
      "engine": "openairedatasets",
      "parsed_url": [
        "https",
        "doi.org",
        "/10.1037/e578892011-002",
        "",
        "",
        ""
      ],
      "template": "default.html",
      "engines": [
        "openairedatasets"
      ],
      "positions": [
        10
      ],
      "score": 0.1,
      "category": "science"
    },
    {
      "url": "https://doi.org/10.1090/s0002-9939-96-03173-5",
      "title": "The cost of computing integers",
      "content": "We analyse the growth rate of a number theoretic function related to the operational complexity of integers",
      "engine": "openairepublications",
      "parsed_url": [
        "https",
        "doi.org",
        "/10.1090/s0002-9939-96-03173-5",
        "",
        "",
        ""
      ],
      "template": "default.html",
      "engines": [
        "openairepublications"
      ],
      "positions": [
        10
      ],
      "score": 0.1,
      "category": "science"
    },
    {
      "template": "paper.html",
      "type": "pdf",
      "url": "https://link.springer.com/article/10.1007/s10543-009-0226-z",
      "title": "New iterations of R-order four with reduced computational cost",
      "authors": [
        "JA Ezquerro",
        "MA Hernández"
      ],
      "publisher": "Springer",
      "journal": "BIT Numerical Mathematics",
      "publishedDate": "2009-01-01T00:00:00",
      "content": "… In this paper, we are interested in constructing some multipoint methods with order of convergence four and good computational cost. Moreover, the construction of these methods is …",
      "comments": "",
      "html_url": null,
      "pdf_url": "https://www.researchgate.net/profile/Jose-Ezquerro-2/publication/225881272_New_iterations_of_R-order_four_with_reduced_computational_cost/links/0c96052e0db02bc6ae000000/New-iterations-of-R-order-four-with-reduced-computational-cost.pdf",
      "engine": "google scholar",
      "parsed_url": [
        "https",
        "link.springer.com",
        "/article/10.1007/s10543-009-0226-z",
        "",
        "",
        ""
      ],
      "engines": [
        "google scholar"
      ],
      "positions": [
        10
      ],
      "score": 0.1,
      "category": "science"
    },
    {
      "template": "paper.html",
      "url": "http://arxiv.org/abs/1302.3291v1",
      "title": "Petri Nets with Time and Cost",
      "publishedDate": "2013-02-14T02:26:37",
      "content": "We consider timed Petri nets, i.e., unbounded Petri nets where each token carries a real-valued clock. Transition arcs are labeled with time intervals, which specify constraints on the ages of tokens. Our cost model assigns token storage costs per time unit to places, and firing costs to transitions. We study the cost to reach a given control-state. In general, a cost-optimal run may not exist. However,we show that the infimum of the costs is computable.",
      "doi": "10.4204/EPTCS.107.3",
      "authors": [
        "Parosh Aziz Abdulla",
        "Richard Mayr"
      ],
      "journal": "EPTCS 107, 2013, pp. 9-24",
      "tags": [
        "cs.LO",
        "D.2.4"
      ],
      "comments": "In Proceedings Infinity 2012, arXiv:1302.3105",
      "pdf_url": "http://arxiv.org/pdf/1302.3291v1",
      "engine": "arxiv",
      "parsed_url": [
        "http",
        "arxiv.org",
        "/abs/1302.3291v1",
        "",
        "",
        ""
      ],
      "engines": [
        "arxiv"
      ],
      "positions": [
        10
      ],
      "score": 0.1,
      "category": "science"
    }
  ],
  "answers": [],
  "corrections": [],
  "infoboxes": [],
  "suggestions": [
    "computational cost memory requirements",
    "accuracy and low computational cost",
    "computational cost density functional theory",
    "computational cost reduce",
    "algorithms computational cost",
    "prohibitive computational cost",
    "accuracy computational cost",
    "low computational cost"
  ],
  "unresponsive_engines": [
    [
      "google",
      "Suspended: too many requests"
    ],
    [
      "pubmed",
      "Suspended: too many requests"
    ]
  ]
}